my_type=hypothesis
proj=hdfs
u_test=org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list[1]=dfs.datanode.du.reserved@@@hdfs:DataNode@@@-1@@@0@@@16384
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-1@@@0@@@16384
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 45284239348
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-1@@@0@@@16384
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 27866959336
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 28562240451
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 29400486075
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 33122154638
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 32315264214
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 46004518071
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-1@@@0@@@16384
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 28174497795
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 28855365356
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 29076307579
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 28405487981
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 31279494491
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 49141772328
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-1@@@0@@@16384
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 34864211969
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 28352333006
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 46622094329
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-1@@@0@@@16384
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 28370089122
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 29870596712
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 45274172127
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-1@@@0@@@16384
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 31198563789
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 28770150905
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 50733575152
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-1@@@0@@@16384
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 34158994085
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 31186564363
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 50110618075
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-1@@@0@@@16384
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 29244858690
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 29362913439
---> v1v1 and v2v2 test test suceeded.
early stop after 7 is satisfied
v1v2 failed with probability 7 out of 9
v1v1v2v2 failed with probability 0 out of 9
Total execution time in seconds : 935
0
