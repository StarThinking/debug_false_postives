my_type=hypothesis
proj=hdfs
u_test=org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list[1]=dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@16384@@@0
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@16384@@@0
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 42093930126
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@16384@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 22673291483
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 29458469316
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 26169934353
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 28472364482
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 30003977092
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 25687767942
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 24691282056
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 23338357573
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 24374398449
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 24558550661
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 27774591958
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 26034514936
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 26880273492
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 25600212520
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 39650213247
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@16384@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 22697437114
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 23279201487
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 23248373219
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 21596233733
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 22461760754
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 41543625675
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@16384@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 28367704069
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 25055785316
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 42726710684
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@16384@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 25582082508
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 23823232757
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 44240925400
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@16384@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 22747918772
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 22297482862
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 40797261475
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@16384@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 24616899971
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 22414282094
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 41411508729
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@16384@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727734272 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 30165645627
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 26397333899
---> v1v1 and v2v2 test test suceeded.
early stop after 7 is satisfied
v1v2 failed with probability 7 out of 12
v1v1v2v2 failed with probability 0 out of 12
Total execution time in seconds : 1022
0
