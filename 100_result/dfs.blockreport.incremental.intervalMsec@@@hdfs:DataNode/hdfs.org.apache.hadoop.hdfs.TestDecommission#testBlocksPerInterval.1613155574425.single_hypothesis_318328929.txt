my_type=hypothesis
proj=hdfs
u_test=org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list[1]=dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@0@@@1000
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@0@@@1000
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 13776712887
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@0@@@1000
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 13307191212
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 16822742273
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 13455642783
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@0@@@1000
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 13370735824
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 15697030685
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 14015858573
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@0@@@1000
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 16948349147
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 19167978326
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 16197315998
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@0@@@1000
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 14261410306
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 16813232379
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 15257469069
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 14727785281
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 17390822488
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 13957369209
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@0@@@1000
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 14269386652
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 16109381737
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 16039369516
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@0@@@1000
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1253)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 14253592526
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 16474000235
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 13038045610
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@0@@@1000
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<2> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<2> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1247)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 14596784040
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 16850633948
---> v1v1 and v2v2 test test suceeded.
early stop after 7 is satisfied
v1v2 failed with probability 7 out of 8
v1v1v2v2 failed with probability 0 out of 8
Total execution time in seconds : 366
0
