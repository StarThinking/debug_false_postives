my_type=hypothesis
proj=hdfs
u_test=org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list[1]=dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@1000@@@0
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@1000@@@0
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 15182760210
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 16359728651
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 12792338546
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 13102362809
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@1000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 18493224410
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 17176983290
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 14720018936
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 17780413333
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 14279504399
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 13388750332
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 15384219229
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 15306102234
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 14708735488
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 18133652412
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 15372991168
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 14920409064
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@1000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 16556308559
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 15582586462
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 13609902488
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@1000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1253)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 18930715397
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 16567725008
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 17004761557
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 17173024481
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 15068016043
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 16132744142
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@1000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1253)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 19772314422
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 16625764850
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 13869235512
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@1000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1253)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 17715505001
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 17281256024
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 14489447635
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 15983812138
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 15716191427
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 16128115407
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@1000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1253)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 19192589416
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 17821680405
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 14053948044
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@1000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 18320129494
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 16993563704
---> v1v1 and v2v2 test test suceeded.
early stop after 7 is satisfied
v1v2 failed with probability 7 out of 13
v1v1v2v2 failed with probability 0 out of 13
Total execution time in seconds : 627
0
