my_type=hypothesis
proj=hdfs
u_test=org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list[1]=dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@10000000@@@0
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@10000000@@@0
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 26526577887
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1253)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 28323445976
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 28238882654
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 24567366394
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1253)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 25823727521
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 20494523217
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 18943180102
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 19334036843
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 15526240690
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 20542724718
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 24888569181
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 16509592779
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 18353088618
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 26275835643
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 19471123503
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 17643918403
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 23457520793
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 28352100485
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 18249612364
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 20631925354
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 21576450436
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 25402857557
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 25673006684
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 23135888918
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 25102038724
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 26007048984
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 20336772779
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 21706141843
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 33705065757
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 22652936875
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 21270831219
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 25680959509
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 21907938782
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 23208844276
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1253)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 29893056617
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 25602857922
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 20239705839
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-1@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1253)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 31525716488
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 31520322136
---> v1v1 and v2v2 test test suceeded.
early stop after 7 is satisfied
v1v2 failed with probability 7 out of 13
v1v1v2v2 failed with probability 0 out of 13
Total execution time in seconds : 918
0
