my_type=hypothesis
proj=hdfs
u_test=org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list[1]=dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 26624566156
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<2> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<2> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1247)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 25530066717
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 19944470694
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 25217669826
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 24480558957
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 19509997757
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 18662437376
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 28742277420
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 22214316764
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 20898595581
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<2> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<2> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1247)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 24564972190
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 24470744379
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 18380296128
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 24799618291
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 21691559096
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 20843688694
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<2> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<2> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1247)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 27541300622
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 20614966752
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 18595108315
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<2> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<2> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1247)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 22071744480
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 16587997088
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 18193409982
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1253)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 23538745428
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 19965768680
---> v1v1 or v2v2 test failed.
v1v1 failed in a hypo test
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v1
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<2> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<2> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1247)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 18506571760
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 20436036668
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 18117481236
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 23405301149
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<2> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<2> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1247)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 26558573149
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 18920205642
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 19218029233
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<2> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<2> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1247)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 22620062827
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 20095766957
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 21685422229
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 23648799584
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 23355019479
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 20816692320
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<2> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<2> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1247)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 20907137672
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 17422070499
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 24301697486
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 24349010992
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 22616726696
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 21292264567
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 22158803698
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 17562446441
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 26048226614
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<2> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<2> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1247)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 26070506695
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 23622871484
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 21574735257
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<2> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<2> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1247)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 29077962381
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 26972027104
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 23883091271
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 27339900471
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 20656933377
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 28950308870
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 29231536730
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 24899540066
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 27970811747
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@10000000@@@0
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<3>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 26652994531
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 26057731238
---> v1v1 and v2v2 test test suceeded.
v1v2 failed with probability 18 out of 20
v1v1v2v2 failed with probability 1 out of 20
Total execution time in seconds : 1370
0
