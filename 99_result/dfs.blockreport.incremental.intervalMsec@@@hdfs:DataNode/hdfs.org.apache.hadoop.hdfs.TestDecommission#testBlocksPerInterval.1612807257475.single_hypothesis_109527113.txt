my_type=hypothesis
proj=hdfs
u_test=org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list[1]=dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@0@@@10000000
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@0@@@10000000
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 15877563422
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@0@@@10000000
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 18627513095
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 24480351624
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 21711158913
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@0@@@10000000
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 24967829656
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 18711090952
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 15550842633
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 15125808915
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 23767333944
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 26845318143
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@0@@@10000000
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 24116860307
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 28269957088
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 23291635212
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 26949258828
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 25943209893
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 20478534759
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 21500977280
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 18720882518
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 19207545258
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@0@@@10000000
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1253)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 24958911438
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 24778400782
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 25540718630
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 25531111865
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 27592785361
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 23785741359
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@0@@@10000000
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 22230255751
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 30828041424
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 23921753973
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 24025819915
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 24844728976
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 21045035541
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@0@@@10000000
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1253)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 20066787141
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 28545402264
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v2 running time = 20381572280
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
h_list: dfs.blockreport.incremental.intervalMsec@@@hdfs:DataNode@@@-2@@@0@@@10000000
vv_mode: v1v2
result: FAIL
failureMessage: Unexpected # of nodes checked expected:<1> but was:<2>
stackTrace: java.lang.AssertionError: Unexpected # of nodes checked expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.hadoop.hdfs.TestDecommission.doDecomCheck(TestDecommission.java:1268)
	at org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval(TestDecommission.java:1250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v1v1 running time = 20046984662
updating test result for file org.apache.hadoop.hdfs.TestDecommission#testBlocksPerInterval
v2v2 running time = 25984035084
---> v1v1 and v2v2 test test suceeded.
early stop after 7 is satisfied
v1v2 failed with probability 7 out of 12
v1v1v2v2 failed with probability 0 out of 12
Total execution time in seconds : 828
0
