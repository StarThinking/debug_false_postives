my_type=hypothesis
proj=hdfs
u_test=org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list[1]=dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@0@@@16384
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@0@@@16384
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 27854326737
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 33558708686
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 32194704294
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 51576347101
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@0@@@16384
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727799808 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727799808 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 33411408916
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 32374983232
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 48281281732
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@0@@@16384
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727799808 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727799808 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 35873174646
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 29827338698
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 33019435132
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 27305799714
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 36416388328
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 54130397368
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@0@@@16384
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727799808 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727799808 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 34995750267
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 35746312886
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 35765739520
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 25881975735
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 30932405898
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 28127481930
---> v1v2 test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 32570041040
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 36205678744
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 51226555126
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@0@@@16384
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727799808 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727799808 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 29855635578
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 33155646891
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 43074306467
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@0@@@16384
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727799808 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727799808 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 32980754558
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 30202951388
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 51779564011
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@0@@@16384
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727799808 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727799808 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 37258225333
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 32030470378
---> v1v1 and v2v2 test test suceeded.
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v2 running time = 47044962351
---> v1v2 test failed.
proj: hdfs
u_test: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
h_list: dfs.datanode.du.reserved@@@hdfs:DataNode@@@-2@@@0@@@16384
vv_mode: v1v2
result: FAIL
failureMessage: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727799808 Expected = 1796727767040 Vol Fails = 0 Expected = 0
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 2 Expected = 2 Dead = 1 Expected = 1 Total capacity = 1796727799808 Expected = 1796727767040 Vol Fails = 0 Expected = 0
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testConfigureMinValidVolumes(TestDataNodeVolumeFailureToleration.java:171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)


updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v1v1 running time = 29432855454
updating test result for file org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration#testConfigureMinValidVolumes
v2v2 running time = 31597616287
---> v1v1 and v2v2 test test suceeded.
early stop after 7 is satisfied
v1v2 failed with probability 7 out of 11
v1v1v2v2 failed with probability 0 out of 11
Total execution time in seconds : 1185
0
